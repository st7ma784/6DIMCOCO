{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5\",\n",
    "    resource_group_name=\"sparc2023-workspace-xudyu-rg\",\n",
    "    workspace_name=\"sparc2023-ws-xudyu\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name conda-6DIM is registered to workspace, the environment version is 56\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "project_dir=\".\"\n",
    "dependencies_dir = os.path.join(project_dir,\"dependencies/\")\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=\"conda-6DIM\",\n",
    "    description=\"env for 6DIMCOCO experiments\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\"\n",
    "    #set OS var\n",
    "    \n",
    "    )\n",
    "\n",
    "env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/data/6DIMCOCO' 'https://sparc2023saxudyu.blob.core.windows.net/117b81e5-7ebd-46cb-9532-7489fe432654-122199x1zljbkwsay56dq9t7ad/6DIMCOCO' \n",
      "\n",
      "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n",
      "\u001b[32mUploading 6DIMCOCO (177.41 MBs): 100%|██████████| 177407116/177407116 [00:06<00:00, 27973664.97it/s] \n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>6DIMCOCO</td><td>jolly_bridge_3mttnfpyxh</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/jolly_bridge_3mttnfpyxh?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'jolly_bridge_3mttnfpyxh', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '9bcfdfe8a0b01b874737449bc1a30fdf350749dc', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'sparc-v100-low-priority', 'ContentSnapshotId': '0a00af0d-79fa-4f89-8d46-c789232177eb'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/jolly_bridge_3mttnfpyxh', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0ad95bb100>, 'serialize': <msrest.serialization.Serializer object at 0x7f0ad9637c40>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'ContrastiveTraining-6D-StephenM-monothread-pathjoin', 'experiment_name': '6DIMCOCO', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/jolly_bridge_3mttnfpyxh?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'job_outputs': {'annot': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/', 'mode': 'rw_mount'}, 'log': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/logs/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.jolly_bridge_3mttnfpyxh', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f0ad9637e80>}, 'outputs': {'annot': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f0ad9637b20>, 'log': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f0ad9637df0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f0ad9637af0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'jolly_bridge_3mttnfpyxh', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0ad95bb100>, 'serialize': <msrest.serialization.Serializer object at 0x7f0ad9637f40>, 'command': 'python launch.py --num_trials -1 --devices 4 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/5852f022-c5f7-419c-bdea-44598e34e52c/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/56', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f0ad97dbd00>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'ContrastiveTraining-6D-StephenM-monothread-pathjoin', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'outputs': {'annot': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/', 'mode': 'rw_mount'}, 'log': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/logs/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.jolly_bridge_3mttnfpyxh', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/jolly_bridge_3mttnfpyxh?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f0ad95bb100>}, 'instance_id': 'f6298dba-abae-42f1-a841-8a3a7c8dce41', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f0ad97dbd00>, 'environment_variables': {}, 'environment': 'conda-6DIM:56', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/logs/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "inputs={ \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "registered_model_name = \"Contrastive trained DETR Model\"\n",
    "job = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials -1 --devices 4 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",\n",
    "    environment=pipeline_job_env.name+\":\"+pipeline_job_env.version,\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"6DIMCOCO\",\n",
    "    display_name=\"ContrastiveTraining-6D-StephenM-monothread-pathjoin\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\":1,\n",
    "        \"node_count\": 1,\n",
    "        \"instance_count\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/wheat_picture_2968p26wys?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"DataNew\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/v2/\",\n",
    "                        mode=InputOutputModes.UPLOAD\n",
    "                        ),\n",
    "    \"input_data\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT,\n",
    "                        ),\n",
    "                        }\n",
    "\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{outputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOWSweep\",\n",
    "    display_name=\"BigSweep\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs={\n",
    "        \n",
    "        \"annotations\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([\"auto\"]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        #\"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3.0,3.5,4.0,6.0,0])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage\n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIPSWEEP\"\n",
    "sweep_job.experiment_name = \"StephenMCLIPHighDimSweep\"\n",
    "sweep_job.description = \"Runahyperparametersweep6or3Drepo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 6DIMCOCO (84.87 MBs): 100%|██████████| 84869030/84869030 [00:01<00:00, 59438882.90it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>downloadmagenet</td><td>cool_shelf_gnl95gtgmz</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'cool_shelf_gnl95gtgmz', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '6782a05dbe3775e948661dfda376c3a5f5f69b8a', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '7c23b79b-17f0-4425-aa7e-bb1e2e78a537'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/cool_shelf_gnl95gtgmz', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862b80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'imgnetdownload', 'experiment_name': 'downloadmagenet', 'compute': 'smander', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f5d074c6220>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f5d074c63d0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'cool_shelf_gnl95gtgmz', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862760>, 'command': 'python BuildImagenet.py --data_path ${{inputs.input_data}}', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/d1d1d178-a6bc-4566-ab90-5fab2a1aecfe/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/32', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'imgnetdownload', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>}, 'instance_id': 'aacb9e0a-f0b3-4607-97e5-d3a0a6a72a73', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'environment_variables': {}, 'environment': 'conda-6DIM:32', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "inputs={\n",
    "\n",
    "       \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT),\n",
    "}\n",
    "registered_model_name = \"buildimagenet\"\n",
    "job = command(\n",
    "    code=os.path.join(project_dir),  # location of source code\n",
    "    command=\"python BuildImagenet.py --data_path ${{inputs.input_data}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"downloadmagenet\",\n",
    "    display_name=\"imgnetdownload\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1061\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1060\u001b[0m local_path \u001b[39m=\u001b[39m Path(base_path \u001b[39mor\u001b[39;00m Path\u001b[39m.\u001b[39mcwd(), entry\u001b[39m.\u001b[39mpath)\u001b[39m.\u001b[39mresolve()\n\u001b[0;32m-> 1061\u001b[0m entry\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m _upload_and_generate_remote_uri(\n\u001b[1;32m   1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_scope,\n\u001b[1;32m   1063\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations,\n\u001b[1;32m   1064\u001b[0m     local_path,\n\u001b[1;32m   1065\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[1;32m   1066\u001b[0m     show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[1;32m   1067\u001b[0m )\n\u001b[1;32m   1068\u001b[0m \u001b[39m# TODO : Move this part to a common place\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:328\u001b[0m, in \u001b[0;36m_upload_and_generate_remote_uri\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress)\u001b[0m\n\u001b[1;32m    327\u001b[0m asset_name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4())\n\u001b[0;32m--> 328\u001b[0m artifact_info \u001b[39m=\u001b[39m _upload_to_datastore(\n\u001b[1;32m    329\u001b[0m     operation_scope\u001b[39m=\u001b[39;49moperation_scope,\n\u001b[1;32m    330\u001b[0m     datastore_operation\u001b[39m=\u001b[39;49mdatastore_operation,\n\u001b[1;32m    331\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    332\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[1;32m    333\u001b[0m     asset_name\u001b[39m=\u001b[39;49masset_name,\n\u001b[1;32m    334\u001b[0m     artifact_type\u001b[39m=\u001b[39;49martifact_type,\n\u001b[1;32m    335\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    336\u001b[0m )\n\u001b[1;32m    338\u001b[0m path \u001b[39m=\u001b[39m artifact_info\u001b[39m.\u001b[39mrelative_path\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:299\u001b[0m, in \u001b[0;36m_upload_to_datastore\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress, asset_name, asset_version, asset_hash, ignore_file, sas_uri, blob_uri)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m asset_hash:\n\u001b[0;32m--> 299\u001b[0m     asset_hash \u001b[39m=\u001b[39m get_object_hash(path, ignore_file)\n\u001b[1;32m    300\u001b[0m artifact \u001b[39m=\u001b[39m upload_artifact(\n\u001b[1;32m    301\u001b[0m     \u001b[39mstr\u001b[39m(path),\n\u001b[1;32m    302\u001b[0m     datastore_operation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m     sas_uri\u001b[39m=\u001b[39msas_uri,\n\u001b[1;32m    311\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:261\u001b[0m, in \u001b[0;36mget_object_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m Path(path)\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 261\u001b[0m     object_hash \u001b[39m=\u001b[39m _get_dir_hash(directory\u001b[39m=\u001b[39;49mpath, _hash\u001b[39m=\u001b[39;49m_hash, ignore_file\u001b[39m=\u001b[39;49mignore_file)\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:232\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 232\u001b[0m         _hash \u001b[39m=\u001b[39m _get_dir_hash(path, _hash, ignore_file)\n\u001b[1;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:232\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 232\u001b[0m         _hash \u001b[39m=\u001b[39m _get_dir_hash(path, _hash, ignore_file)\n\u001b[1;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:226\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m _hash\u001b[39m.\u001b[39mupdate(path\u001b[39m.\u001b[39;49mname\u001b[39m.\u001b[39;49mencode())\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mislink(path):  \u001b[39m# ensure we're hashing the contents of the linked file\u001b[39;00m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:910\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_inputs(job\u001b[39m.\u001b[39;49m_job_inputs\u001b[39m.\u001b[39;49mvalues(), job\u001b[39m.\u001b[39;49m_base_path)\n\u001b[1;32m    911\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     \u001b[39m# If the job object doesn't have \"inputs\" attribute, we don't need to resolve. E.g. AutoML jobs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:976\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_inputs\u001b[0;34m(self, entries, base_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_input(entry, base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1074\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1075\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1076\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMet \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1077\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[1;32m   1078\u001b[0m         no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1079\u001b[0m         error\u001b[39m=\u001b[39me,\n\u001b[1;32m   1080\u001b[0m         error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[1;32m   1081\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1082\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mValidationException\u001b[0m: Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcp -r $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39minputs.source_path}} $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.destination_path}}\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     compute\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msmander\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     outputs\u001b[39m=\u001b[39moutputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Submit the job\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:608\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarshmallow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m SchemaValidationError\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[0;32m--> 608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_exception_helper.py:295\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m--> 295\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(formatted_error)\n",
      "\u001b[0;31mException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_path = \".\"\n",
    "destination_path = \"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/\"\n",
    "# # Run the azcopy command to copy the directory\n",
    "# subprocess.run([\"./azcopy\", \"copy\", source_path, destination_path, \"--recursive\"])\n",
    "\n",
    "# Define the input and output paths\n",
    "inputs = {\n",
    "    \"source_path\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                         path=source_path,\n",
    "                         mode=InputOutputModes.RO_MOUNT),\n",
    "}\n",
    "\n",
    "outputs = {\n",
    "    \"destination_path\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                             path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data2/\",\n",
    "                               mode=InputOutputModes.RW_MOUNT),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Create your command\n",
    "job = command(\n",
    "    command=\"cp -r ${{inputs.source_path}} ${{outputs.destination_path}}\",\n",
    "    compute=\"smander\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    experiment_name=\"AzCopyJob\",\n",
    "    display_name=\"AzCopy\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "ml_client.create_or_update(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "Inputs to job does not contain 'input_data' referenced in command",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m sweep_job\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun a hyperparameter sweep 6D repo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# submit the sweep\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m returned_sweep_job \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep_job\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# get a URL for the status of the job\u001b[39;00m\n\u001b[1;32m     63\u001b[0m returned_sweep_job\u001b[38;5;241m.\u001b[39mservices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mendpoint\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:1063\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_or_update\u001b[39m(\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1049\u001b[0m     entity: T,\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1051\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:1122\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;129m@_create_or_update\u001b[39m\u001b[38;5;241m.\u001b[39mregister(Job)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(entity: Job, operations, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1121\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating or updating job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAzureMLResourceType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJOB\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:350\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 350\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    353\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:656\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(prop_name \u001b[38;5;129;01min\u001b[39;00m job\u001b[38;5;241m.\u001b[39mproperties \u001b[38;5;28;01mfor\u001b[39;00m prop_name \u001b[38;5;129;01min\u001b[39;00m git_props):\n\u001b[1;32m    655\u001b[0m     job\u001b[38;5;241m.\u001b[39mproperties \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob\u001b[38;5;241m.\u001b[39mproperties, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgit_props}\n\u001b[0;32m--> 656\u001b[0m rest_job_resource \u001b[38;5;241m=\u001b[39m \u001b[43mto_rest_job_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# Make a copy of self._kwargs instead of contaminate the original one\u001b[39;00m\n\u001b[1;32m    659\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/to_rest_functions.py:42\u001b[0m, in \u001b[0;36m_\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@to_rest_job_object\u001b[39m\u001b[38;5;241m.\u001b[39mregister(Job)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(job: Job) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JobBaseData:\n\u001b[0;32m---> 42\u001b[0m     rest_job \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_rest_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     generate_defaults(job, rest_job)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rest_job\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/sweep/sweep_job.py:193\u001b[0m, in \u001b[0;36mSweepJob._to_rest_object\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mcommand \u001b[38;5;241m=\u001b[39m map_single_brackets_and_warn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mcommand)\n\u001b[1;32m    191\u001b[0m search_space \u001b[38;5;241m=\u001b[39m {param: space\u001b[38;5;241m.\u001b[39m_to_rest_object() \u001b[38;5;28;01mfor\u001b[39;00m (param, space) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_space\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 193\u001b[0m \u001b[43mvalidate_inputs_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m search_space\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    195\u001b[0m     validate_key_contains_allowed_characters(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/_input_output_helpers.py:151\u001b[0m, in \u001b[0;36mvalidate_inputs_for_command\u001b[0;34m(command, inputs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_inputs_for_command\u001b[39m(command: \u001b[38;5;28mstr\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43m_validate_inputs_for\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/_input_output_helpers.py:141\u001b[0m, in \u001b[0;36m_validate_inputs_for\u001b[0;34m(input_consumer_name, input_consumer, inputs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m optional_inputs:\n\u001b[1;32m    140\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to job does not contain \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m referenced in \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m input_consumer_name\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    142\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(key),\n\u001b[1;32m    143\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[key]\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    144\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    145\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    146\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m    147\u001b[0m     )\n",
      "\u001b[0;31mValidationException\u001b[0m: Inputs to job does not contain 'input_data' referenced in command"
     ]
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=\".\",  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOSWEEP2\",\n",
    "    display_name=\"6DIMSweepStephenMd1\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([1]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        \"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3.0,3.5,4.0,6.0])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-SWEEP2\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-HighDimSweep\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep 6D repo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>datasetcleaning</td><td>salmon_pummelo_w76gxzm6fs</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/salmon_pummelo_w76gxzm6fs?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'salmon_pummelo_w76gxzm6fs', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '67bd2407bb9e995d97051c9234ceb7d4afe1f688', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/salmon_pummelo_w76gxzm6fs', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6e18550>, 'serialize': <msrest.serialization.Serializer object at 0x7efcc6e18610>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'temp', 'experiment_name': 'datasetcleaning', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/salmon_pummelo_w76gxzm6fs?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/logs/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.salmon_pummelo_w76gxzm6fs', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'remove': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7efcc6e23c40>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7efcc6e237f0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'salmon_pummelo_w76gxzm6fs', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6e18550>, 'serialize': <msrest.serialization.Serializer object at 0x7efcc6e186a0>, 'command': 'rm -rf ${{outputs.remove}}', 'code': None, 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/39', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7efcc6e186d0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'temp', 'is_deterministic': True, 'inputs': {}, 'outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/logs/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.salmon_pummelo_w76gxzm6fs', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/salmon_pummelo_w76gxzm6fs?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6e18550>}, 'instance_id': '789c8dae-aa5b-4585-9566-4e0b2f6bac15', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7efcc6e186d0>, 'environment_variables': {}, 'environment': 'conda-6DIM:39', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create job to delete : the file at  azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations\n",
    "\n",
    "outputToEdit={\n",
    "    \"remove\":Output(type=AssetTypes.URI_FILE,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/logs/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),    \n",
    "}\n",
    "\n",
    "job = command(\n",
    "    command=\"rm -rf ${{outputs.remove}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"datasetcleaning\",\n",
    "    display_name=\"temp\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputToEdit,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
