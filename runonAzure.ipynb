{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5\",\n",
    "    resource_group_name=\"sparc2023-workspace-xudyu-rg\",\n",
    "    workspace_name=\"sparc2023-ws-xudyu\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name conda-6DIM is registered to workspace, the environment version is 36\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "project_dir=\"/data/6DIMCOCO/\"\n",
    "dependencies_dir = os.path.join(project_dir,\"dependencies/\")\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=\"conda-6DIM\",\n",
    "    description=\"env for 6DIMCOCO experiments\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\"\n",
    "    #set OS var\n",
    "    \n",
    "    )\n",
    "\n",
    "env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m registered_model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mContrastive trained DETR Model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     code\u001b[39m=\u001b[39mproject_dir,  \u001b[39m# location of source code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython launch.py --num_trials 0 --dir $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39minputs.input_data}} --log_path $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.log}} --annotations $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.annot}}\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1108\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n\u001b[1;32m   1107\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, Command):\n\u001b[0;32m-> 1108\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_command_job(job, resolver)\n\u001b[1;32m   1109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, ImportJob):\n\u001b[1;32m   1110\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_import_job(job, resolver)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1146\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_command_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1137\u001b[0m         message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(job\u001b[39m.\u001b[39mcode),\n\u001b[1;32m   1138\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1145\u001b[0m     job\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1146\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1147\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1148\u001b[0m     )\n\u001b[1;32m   1149\u001b[0m job\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1150\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"DataNew\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/v2/\",\n",
    "                        mode=InputOutputModes.UPLOAD\n",
    "                        ),\n",
    "}\n",
    "\n",
    "\n",
    "inputs={ \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"annotations\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "registered_model_name = \"Contrastive trained DETR Model\"\n",
    "job = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",\n",
    "    environment=pipeline_job_env.name+\":\"+pipeline_job_env.version,\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"6DIMCOCO\",\n",
    "    display_name=\"ContrastiveTraining-6D-StephenM-monothread-pathjoin\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "        \"node_count\": 1,\n",
    "        \"instance_count\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m sweep_job\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRun a hyperparameter sweep 6D repo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# submit the sweep\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m returned_sweep_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(sweep_job)\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# get a URL for the status of the job\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m returned_sweep_job\u001b[39m.\u001b[39mservices[\u001b[39m\"\u001b[39m\u001b[39mStudio\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendpoint\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1116\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_parallel_job(job, resolver)\n\u001b[1;32m   1115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, SweepJob):\n\u001b[0;32m-> 1116\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_sweep_job(job, resolver)\n\u001b[1;32m   1117\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, AutoMLJob):\n\u001b[1;32m   1118\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_automl_job(job, resolver, inside_pipeline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1198\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_sweep_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[39m\"\"\"Resolve arm_id for SweepJob.\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1197\u001b[0m     job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1198\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mtrial\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1199\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1200\u001b[0m     )\n\u001b[1;32m   1201\u001b[0m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1202\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"DataNew\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/v2/\",\n",
    "                        mode=InputOutputModes.UPLOAD\n",
    "                        ),\n",
    "                        }\n",
    "\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOWSweep\",\n",
    "    display_name=\"BigSweep\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs={\n",
    "        \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"annotations\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([4]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        #\"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3,6])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"smander\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage\n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIPSWEEP\"\n",
    "sweep_job.experiment_name = \"StephenMCLIPHighDimSweep\"\n",
    "sweep_job.description = \"Runahyperparametersweep6or3Drepo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 6DIMCOCO (84.87 MBs): 100%|██████████| 84869030/84869030 [00:01<00:00, 59438882.90it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>downloadmagenet</td><td>cool_shelf_gnl95gtgmz</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'cool_shelf_gnl95gtgmz', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '6782a05dbe3775e948661dfda376c3a5f5f69b8a', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '7c23b79b-17f0-4425-aa7e-bb1e2e78a537'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/cool_shelf_gnl95gtgmz', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862b80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'imgnetdownload', 'experiment_name': 'downloadmagenet', 'compute': 'smander', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f5d074c6220>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f5d074c63d0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'cool_shelf_gnl95gtgmz', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862760>, 'command': 'python BuildImagenet.py --data_path ${{inputs.input_data}}', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/d1d1d178-a6bc-4566-ab90-5fab2a1aecfe/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/32', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'imgnetdownload', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>}, 'instance_id': 'aacb9e0a-f0b3-4607-97e5-d3a0a6a72a73', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'environment_variables': {}, 'environment': 'conda-6DIM:32', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "inputs={\n",
    "\n",
    "       \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT),\n",
    "}\n",
    "registered_model_name = \"buildimagenet\"\n",
    "job = command(\n",
    "    code=os.path.join(project_dir),  # location of source code\n",
    "    command=\"python BuildImagenet.py --data_path ${{inputs.input_data}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"downloadmagenet\",\n",
    "    display_name=\"imgnetdownload\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/data/ImageNet-2012' 'https://sparc2023saxudyu.blob.core.windows.net/azureml-blobstore-117b81e5-7ebd-46cb-9532-7489fe432654/LocalUpload/c83f3f94bb746fcaaa408156eabfc466/ImageNet-2012' \n",
      "\n",
      "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n",
      "Uploading ImageNet-2012 (398326.94 MBs): 100%|██████████| 398326943734/398326943734 [1:24:56<00:00, 78164366.26it/s]  \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>AzCopyJob</td><td>quirky_lock_wj1k5lcp8z</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/quirky_lock_wj1k5lcp8z?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'quirky_lock_wj1k5lcp8z', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '7e48030222f64bdce021a972bd9566d28fb479a6', 'azureml.git.dirty': 'False', '_azureml.ComputeTargetType': 'amlctrain'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/quirky_lock_wj1k5lcp8z', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8bfeed4820>, 'serialize': <msrest.serialization.Serializer object at 0x7f8bfe964130>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'AzCopy', 'experiment_name': 'AzCopyJob', 'compute': 'smander', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/quirky_lock_wj1k5lcp8z?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'source_path': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/c83f3f94bb746fcaaa408156eabfc466/ImageNet-2012/', 'mode': 'direct'}}, 'job_outputs': {'destination_path': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/ImageNet-2012', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.quirky_lock_wj1k5lcp8z', 'mode': 'rw_mount'}}, 'inputs': {'source_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f8bfe964fa0>}, 'outputs': {'destination_path': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f8bfe9642e0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f8bfe9644f0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'quirky_lock_wj1k5lcp8z', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8bfeed4820>, 'serialize': <msrest.serialization.Serializer object at 0x7f8bfe964ca0>, 'command': 'cp -r ${{inputs.source_path}} ${{outputs.destination_path}}', 'code': None, 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/33', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f8bffd318b0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'AzCopy', 'is_deterministic': True, 'inputs': {'source_path': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/c83f3f94bb746fcaaa408156eabfc466/ImageNet-2012/', 'mode': 'direct'}}, 'outputs': {'destination_path': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/ImageNet-2012', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.quirky_lock_wj1k5lcp8z', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/quirky_lock_wj1k5lcp8z?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f8bfeed4820>}, 'instance_id': '3ece8cda-91f0-45d9-804a-e9996d0f0182', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f8bffd318b0>, 'environment_variables': {}, 'environment': 'conda-6DIM:33', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_path = \"/data/ImageNet-2012\"\n",
    "destination_path = \"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/ImageNet-2012\"\n",
    "\n",
    "# # Run the azcopy command to copy the directory\n",
    "# subprocess.run([\"./azcopy\", \"copy\", source_path, destination_path, \"--recursive\"])\n",
    "\n",
    "# Define the input and output paths\n",
    "inputs = {\n",
    "    \"source_path\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                         path=\"/data/ImageNet-2012\",\n",
    "                         mode=InputOutputModes.DIRECT),\n",
    "}\n",
    "\n",
    "outputs = {\n",
    "    \"destination_path\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                             path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/ImageNet-2012\",\n",
    "                               mode=InputOutputModes.RW_MOUNT),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Create your command\n",
    "job = command(\n",
    "    command=\"cp -r ${{inputs.source_path}} ${{outputs.destination_path}}\",\n",
    "    compute=\"smander\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    experiment_name=\"AzCopyJob\",\n",
    "    display_name=\"AzCopy\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "ml_client.create_or_update(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOSWEEP2\",\n",
    "    display_name=\"6DIMSweepStephenMd1\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([1]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        \"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3,6])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-SWEEP2\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-HighDimSweep\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep 6D repo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>datasetcleaning</td><td>goofy_ice_ymxfbczj63</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/goofy_ice_ymxfbczj63?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'goofy_ice_ymxfbczj63', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '6782a05dbe3775e948661dfda376c3a5f5f69b8a', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/goofy_ice_ymxfbczj63', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ffbb03cd2b0>, 'serialize': <msrest.serialization.Serializer object at 0x7ffbb14186d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'temp', 'experiment_name': 'datasetcleaning', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/goofy_ice_ymxfbczj63?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/test2015', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.goofy_ice_ymxfbczj63', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'remove': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7ffbb1418640>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7ffbb1418700>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'goofy_ice_ymxfbczj63', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ffbb03cd2b0>, 'serialize': <msrest.serialization.Serializer object at 0x7ffbb1418bb0>, 'command': 'rm ${{outputs.remove}}', 'code': None, 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/27', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7ffbb11727f0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'temp', 'is_deterministic': True, 'inputs': {}, 'outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/test2015', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.goofy_ice_ymxfbczj63', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/goofy_ice_ymxfbczj63?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ffbb03cd2b0>}, 'instance_id': '1a326611-34ff-4149-88aa-87cf9ec02e2e', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7ffbb11727f0>, 'environment_variables': {}, 'environment': 'conda-6DIM:27', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create job to delete : the file at  azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations\n",
    "\n",
    "outputToEdit={\n",
    "    \"remove\":Output(type=AssetTypes.URI_FILE,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),    \n",
    "}\n",
    "\n",
    "job = command(\n",
    "    command=\"rm ${{outputs.remove}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"datasetcleaning\",\n",
    "    display_name=\"temp\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputToEdit,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
