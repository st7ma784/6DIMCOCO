{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5\",\n",
    "    resource_group_name=\"sparc2023-workspace-xudyu-rg\",\n",
    "    workspace_name=\"sparc2023-ws-xudyu\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name conda-6DIM is registered to workspace, the environment version is 39\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "project_dir=\".\"\n",
    "dependencies_dir = os.path.join(project_dir,\"dependencies/\")\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=\"conda-6DIM\",\n",
    "    description=\"env for 6DIMCOCO experiments\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\"\n",
    "    #set OS var\n",
    "    \n",
    "    )\n",
    "\n",
    "env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m registered_model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mContrastive trained DETR Model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     code\u001b[39m=\u001b[39mproject_dir,  \u001b[39m# location of source code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython launch.py --num_trials 0 --dir $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39minputs.input_data}} --log_path $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.log}} --annotations $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.annot}}\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1108\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n\u001b[1;32m   1107\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, Command):\n\u001b[0;32m-> 1108\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_command_job(job, resolver)\n\u001b[1;32m   1109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, ImportJob):\n\u001b[1;32m   1110\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_import_job(job, resolver)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1146\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_command_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1137\u001b[0m         message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(job\u001b[39m.\u001b[39mcode),\n\u001b[1;32m   1138\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1145\u001b[0m     job\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1146\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1147\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1148\u001b[0m     )\n\u001b[1;32m   1149\u001b[0m job\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1150\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"DataNew\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/v2/\",\n",
    "                        mode=InputOutputModes.UPLOAD\n",
    "                        ),\n",
    "}\n",
    "\n",
    "\n",
    "inputs={ \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"annotations\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "registered_model_name = \"Contrastive trained DETR Model\"\n",
    "job = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",\n",
    "    environment=pipeline_job_env.name+\":\"+pipeline_job_env.version,\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"6DIMCOCO\",\n",
    "    display_name=\"ContrastiveTraining-6D-StephenM-monothread-pathjoin\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "        \"node_count\": 1,\n",
    "        \"instance_count\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m sweep_job\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRun a hyperparameter sweep 6D repo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# submit the sweep\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m returned_sweep_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(sweep_job)\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# get a URL for the status of the job\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W3sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m returned_sweep_job\u001b[39m.\u001b[39mservices[\u001b[39m\"\u001b[39m\u001b[39mStudio\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendpoint\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1116\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_parallel_job(job, resolver)\n\u001b[1;32m   1115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, SweepJob):\n\u001b[0;32m-> 1116\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_sweep_job(job, resolver)\n\u001b[1;32m   1117\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, AutoMLJob):\n\u001b[1;32m   1118\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_automl_job(job, resolver, inside_pipeline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1198\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_sweep_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[39m\"\"\"Resolve arm_id for SweepJob.\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1197\u001b[0m     job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1198\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mtrial\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1199\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1200\u001b[0m     )\n\u001b[1;32m   1201\u001b[0m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1202\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"annot\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),\n",
    "    \"DataNew\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/v2/\",\n",
    "                        mode=InputOutputModes.UPLOAD\n",
    "                        ),\n",
    "                        }\n",
    "\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.log}} --annotations ${{outputs.annot}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOWSweep\",\n",
    "    display_name=\"BigSweep\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs={\n",
    "        \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"annotations\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations/\",\n",
    "                        mode=InputOutputModes.DIRECT,\n",
    "                        ),\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([4]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        #\"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3,6])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"smander\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage\n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIPSWEEP\"\n",
    "sweep_job.experiment_name = \"StephenMCLIPHighDimSweep\"\n",
    "sweep_job.description = \"Runahyperparametersweep6or3Drepo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading 6DIMCOCO (84.87 MBs): 100%|██████████| 84869030/84869030 [00:01<00:00, 59438882.90it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>downloadmagenet</td><td>cool_shelf_gnl95gtgmz</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'cool_shelf_gnl95gtgmz', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '6782a05dbe3775e948661dfda376c3a5f5f69b8a', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '7c23b79b-17f0-4425-aa7e-bb1e2e78a537'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/cool_shelf_gnl95gtgmz', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862b80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'imgnetdownload', 'experiment_name': 'downloadmagenet', 'compute': 'smander', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f5d074c6220>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f5d074c63d0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'cool_shelf_gnl95gtgmz', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>, 'serialize': <msrest.serialization.Serializer object at 0x7f5cee862760>, 'command': 'python BuildImagenet.py --data_path ${{inputs.input_data}}', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/d1d1d178-a6bc-4566-ab90-5fab2a1aecfe/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/32', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'imgnetdownload', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'direct'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.cool_shelf_gnl95gtgmz', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/cool_shelf_gnl95gtgmz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5cee862dc0>}, 'instance_id': 'aacb9e0a-f0b3-4607-97e5-d3a0a6a72a73', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f5cee862b50>, 'environment_variables': {}, 'environment': 'conda-6DIM:32', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "inputs={\n",
    "\n",
    "       \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.DIRECT),\n",
    "}\n",
    "registered_model_name = \"buildimagenet\"\n",
    "job = command(\n",
    "    code=os.path.join(project_dir),  # location of source code\n",
    "    command=\"python BuildImagenet.py --data_path ${{inputs.input_data}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"downloadmagenet\",\n",
    "    display_name=\"imgnetdownload\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1061\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1060\u001b[0m local_path \u001b[39m=\u001b[39m Path(base_path \u001b[39mor\u001b[39;00m Path\u001b[39m.\u001b[39mcwd(), entry\u001b[39m.\u001b[39mpath)\u001b[39m.\u001b[39mresolve()\n\u001b[0;32m-> 1061\u001b[0m entry\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m _upload_and_generate_remote_uri(\n\u001b[1;32m   1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_scope,\n\u001b[1;32m   1063\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations,\n\u001b[1;32m   1064\u001b[0m     local_path,\n\u001b[1;32m   1065\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[1;32m   1066\u001b[0m     show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[1;32m   1067\u001b[0m )\n\u001b[1;32m   1068\u001b[0m \u001b[39m# TODO : Move this part to a common place\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:328\u001b[0m, in \u001b[0;36m_upload_and_generate_remote_uri\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress)\u001b[0m\n\u001b[1;32m    327\u001b[0m asset_name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4())\n\u001b[0;32m--> 328\u001b[0m artifact_info \u001b[39m=\u001b[39m _upload_to_datastore(\n\u001b[1;32m    329\u001b[0m     operation_scope\u001b[39m=\u001b[39;49moperation_scope,\n\u001b[1;32m    330\u001b[0m     datastore_operation\u001b[39m=\u001b[39;49mdatastore_operation,\n\u001b[1;32m    331\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    332\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[1;32m    333\u001b[0m     asset_name\u001b[39m=\u001b[39;49masset_name,\n\u001b[1;32m    334\u001b[0m     artifact_type\u001b[39m=\u001b[39;49martifact_type,\n\u001b[1;32m    335\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    336\u001b[0m )\n\u001b[1;32m    338\u001b[0m path \u001b[39m=\u001b[39m artifact_info\u001b[39m.\u001b[39mrelative_path\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:299\u001b[0m, in \u001b[0;36m_upload_to_datastore\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress, asset_name, asset_version, asset_hash, ignore_file, sas_uri, blob_uri)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m asset_hash:\n\u001b[0;32m--> 299\u001b[0m     asset_hash \u001b[39m=\u001b[39m get_object_hash(path, ignore_file)\n\u001b[1;32m    300\u001b[0m artifact \u001b[39m=\u001b[39m upload_artifact(\n\u001b[1;32m    301\u001b[0m     \u001b[39mstr\u001b[39m(path),\n\u001b[1;32m    302\u001b[0m     datastore_operation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m     sas_uri\u001b[39m=\u001b[39msas_uri,\n\u001b[1;32m    311\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:261\u001b[0m, in \u001b[0;36mget_object_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m Path(path)\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 261\u001b[0m     object_hash \u001b[39m=\u001b[39m _get_dir_hash(directory\u001b[39m=\u001b[39;49mpath, _hash\u001b[39m=\u001b[39;49m_hash, ignore_file\u001b[39m=\u001b[39;49mignore_file)\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:232\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 232\u001b[0m         _hash \u001b[39m=\u001b[39m _get_dir_hash(path, _hash, ignore_file)\n\u001b[1;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:232\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 232\u001b[0m         _hash \u001b[39m=\u001b[39m _get_dir_hash(path, _hash, ignore_file)\n\u001b[1;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m _hash\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:226\u001b[0m, in \u001b[0;36m_get_dir_hash\u001b[0;34m(directory, _hash, ignore_file)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m _hash\u001b[39m.\u001b[39mupdate(path\u001b[39m.\u001b[39;49mname\u001b[39m.\u001b[39;49mencode())\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mislink(path):  \u001b[39m# ensure we're hashing the contents of the linked file\u001b[39;00m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:910\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_inputs(job\u001b[39m.\u001b[39;49m_job_inputs\u001b[39m.\u001b[39;49mvalues(), job\u001b[39m.\u001b[39;49m_base_path)\n\u001b[1;32m    911\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     \u001b[39m# If the job object doesn't have \"inputs\" attribute, we don't need to resolve. E.g. AutoML jobs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:976\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_inputs\u001b[0;34m(self, entries, base_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_job_input(entry, base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1074\u001b[0m, in \u001b[0;36mJobOperations._resolve_job_input\u001b[0;34m(self, entry, base_path)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1075\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1076\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMet \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1077\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[1;32m   1078\u001b[0m         no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported input path value are ARM id, AzureML id, remote uri or local path.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1079\u001b[0m         error\u001b[39m=\u001b[39me,\n\u001b[1;32m   1080\u001b[0m         error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[1;32m   1081\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1082\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mValidationException\u001b[0m: Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcp -r $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39minputs.source_path}} $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.destination_path}}\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     compute\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msmander\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     outputs\u001b[39m=\u001b[39moutputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Submit the job\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:608\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarshmallow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m SchemaValidationError\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[0;32m--> 608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_exception_helper.py:295\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m--> 295\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(formatted_error)\n",
      "\u001b[0;31mException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Supported input path value are ARM id, AzureML id, remote uri or local path.\nMet <class 'UnicodeEncodeError'>:\n'utf-8' codec can't encode character '\\udcc7' in position 1: surrogates not allowed\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_path = \"../.\"\n",
    "destination_path = \"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/\"\n",
    "# # Run the azcopy command to copy the directory\n",
    "# subprocess.run([\"./azcopy\", \"copy\", source_path, destination_path, \"--recursive\"])\n",
    "\n",
    "# Define the input and output paths\n",
    "inputs = {\n",
    "    \"source_path\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                         path=source_path,\n",
    "                         mode=InputOutputModes.RO_MOUNT),\n",
    "}\n",
    "\n",
    "outputs = {\n",
    "    \"destination_path\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                             path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data2/\",\n",
    "                               mode=InputOutputModes.RW_MOUNT),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Create your command\n",
    "job = command(\n",
    "    command=\"cp -r ${{inputs.source_path}} ${{outputs.destination_path}}\",\n",
    "    compute=\"smander\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    experiment_name=\"AzCopyJob\",\n",
    "    display_name=\"AzCopy\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "ml_client.create_or_update(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W6sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m sweep_job\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRun a hyperparameter sweep 6D repo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W6sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# submit the sweep\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W6sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m returned_sweep_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(sweep_job)\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# get a URL for the status of the job\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m returned_sweep_job\u001b[39m.\u001b[39mservices[\u001b[39m\"\u001b[39m\u001b[39mStudio\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendpoint\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1116\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_parallel_job(job, resolver)\n\u001b[1;32m   1115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, SweepJob):\n\u001b[0;32m-> 1116\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_sweep_job(job, resolver)\n\u001b[1;32m   1117\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, AutoMLJob):\n\u001b[1;32m   1118\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_automl_job(job, resolver, inside_pipeline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1198\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_sweep_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[39m\"\"\"Resolve arm_id for SweepJob.\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1197\u001b[0m     job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1198\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mtrial\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1199\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1200\u001b[0m     )\n\u001b[1;32m   1201\u001b[0m job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39mtrial\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1202\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=\".\",  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOSWEEP2\",\n",
    "    display_name=\"6DIMSweepStephenMd1\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([1]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        \"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(list(range(2,8))),\n",
    "        \"dims\":Choice([3,6])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-SWEEP2\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-HighDimSweep\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep 6D repo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>datasetcleaning</td><td>strong_room_fv0nkdk93y</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/strong_room_fv0nkdk93y?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'strong_room_fv0nkdk93y', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '67bd2407bb9e995d97051c9234ceb7d4afe1f688', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/strong_room_fv0nkdk93y', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6f365b0>, 'serialize': <msrest.serialization.Serializer object at 0x7efcc6f3ca90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'temp', 'experiment_name': 'datasetcleaning', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/strong_room_fv0nkdk93y?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/coco/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.strong_room_fv0nkdk93y', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'remove': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7efcc6f3c8b0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7efcc6f3c790>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'strong_room_fv0nkdk93y', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6f365b0>, 'serialize': <msrest.serialization.Serializer object at 0x7efcc6f3c9d0>, 'command': 'rm -rf ${{outputs.remove}}', 'code': None, 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/39', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7efcc6f36cd0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'temp', 'is_deterministic': True, 'inputs': {}, 'outputs': {'remove': {'type': 'uri_file', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/coco/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.strong_room_fv0nkdk93y', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/strong_room_fv0nkdk93y?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7efcc6f365b0>}, 'instance_id': '501792f6-3aee-474a-8d52-04ea75e19895', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7efcc6f36cd0>, 'environment_variables': {}, 'environment': 'conda-6DIM:39', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create job to delete : the file at  azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/annotations\n",
    "\n",
    "outputToEdit={\n",
    "    \"remove\":Output(type=AssetTypes.URI_FILE,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/coco/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        ),    \n",
    "}\n",
    "\n",
    "job = command(\n",
    "    command=\"rm -rf ${{outputs.remove}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"datasetcleaning\",\n",
    "    display_name=\"temp\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputToEdit,\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
