{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5\",\n",
    "    resource_group_name=\"sparc2023-workspace-xudyu-rg\",\n",
    "    workspace_name=\"sparc2023-ws-xudyu\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name conda-6DIM is registered to workspace, the environment version is 24\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "project_dir=\".\"\n",
    "dependencies_dir = os.path.join(project_dir,\"dependencies/\")\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=\"conda-6DIM\",\n",
    "    description=\"env for 6DIMCOCO experiments\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\"\n",
    "    #set OS var\n",
    "    \n",
    "    )\n",
    "\n",
    "env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m inputs\u001b[39m=\u001b[39mInput(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mAssetTypes\u001b[39m.\u001b[39mURI_FOLDER,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                         path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mazureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                         mode\u001b[39m=\u001b[39mInputOutputModes\u001b[39m.\u001b[39mRO_MOUNT\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m registered_model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mContrastive trained DETR Model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     code\u001b[39m=\u001b[39mproject_dir,  \u001b[39m# location of source code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython launch.py --num_trials 0 --dir $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39minputs.input_data}} --log_path $\u001b[39m\u001b[39m{{\u001b[39m\u001b[39moutputs.input_data}}\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     environment\u001b[39m=\u001b[39mpipeline_job_env\u001b[39m.\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpipeline_job_env\u001b[39m.\u001b[39mversion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     compute\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msmander\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     experiment_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m6DIMCOCO\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     display_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mContrastiveTraining-6D-StephenM\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     distribution\u001b[39m=\u001b[39m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPyTorch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprocess_count_per_instance\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnode_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstance_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     outputs\u001b[39m=\u001b[39moutputs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     inputs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39minput_data\u001b[39m\u001b[39m\"\u001b[39m:inputs},\n\u001b[1;32m     <a href='vscode-notebook-cell:/data/6DIMCOCO/runonAzure.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'project_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "outputs = {\n",
    "    \"input_data\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/logs/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        )\n",
    "}\n",
    "inputs=Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RO_MOUNT\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "registered_model_name = \"Contrastive trained DETR Model\"\n",
    "job = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.input_data}}\",\n",
    "    environment=pipeline_job_env.name+\":\"+pipeline_job_env.version,\n",
    "    compute=\"smander\",\n",
    "    experiment_name=\"6DIMCOCO\",\n",
    "    display_name=\"ContrastiveTraining-6D-StephenM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "        \"node_count\": 1,\n",
    "        \"instance_count\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs={\"input_data\":inputs},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading 6DIMCOCO (82.11 MBs): 100%|██████████| 82112152/82112152 [00:01<00:00, 68104748.12it/s] \n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>6DIMCOCO</td><td>bright_sheep_t07k24677t</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/bright_sheep_t07k24677t?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'bright_sheep_t07k24677t', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'a0a3448bb90672e567196fd60e3190e55de9c1b5', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '77cbba02-2a32-4aea-94fc-ecec244bb2f7'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/bright_sheep_t07k24677t', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4d4db1c0>, 'serialize': <msrest.serialization.Serializer object at 0x7f9f4d4db0d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'ContrastiveTraining-6D-StephenM', 'experiment_name': '6DIMCOCO', 'compute': 'smander', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/bright_sheep_t07k24677t?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bright_sheep_t07k24677t', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f9f4d4db6a0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f9f4d4e6ee0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'bright_sheep_t07k24677t', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4d4db1c0>, 'serialize': <msrest.serialization.Serializer object at 0x7f9f4d4dbf10>, 'command': 'python launch.py --num_trials 0 --dir ${{outputs.input_data}} --log_path ././logs', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/6654aee1-4c0e-4adb-b401-c0753ce7b3c2/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/19', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f9f4d4dbaf0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'ContrastiveTraining-6D-StephenM', 'is_deterministic': True, 'inputs': {}, 'outputs': {'input_data': {'type': 'uri_folder', 'path': 'azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bright_sheep_t07k24677t', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/bright_sheep_t07k24677t?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4d4db1c0>}, 'instance_id': '5ff12326-6945-43a8-8f17-0b2db9118a37', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f9f4d4dbaf0>, 'environment_variables': {}, 'environment': 'conda-6DIM:19', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading 6DIMCOCO (82.13 MBs): 100%|██████████| 82130823/82130823 [00:01<00:00, 51189424.70it/s] \n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/icy_mangos_629ncsgqyg?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input,Output\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        '''\n",
    "outputs = {\n",
    "    \"log\": Output(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/logs/\",\n",
    "                        mode=InputOutputModes.RW_MOUNT\n",
    "                        )\n",
    "}\n",
    "\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}} --log_path ${{outputs.log}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOSWEEP\",\n",
    "    display_name=\"6DIMSweepStephenM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    inputs={\n",
    "        \n",
    "        \"input_data\": Input(type=AssetTypes.URI_FOLDER,\n",
    "                        path=\"azureml://subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu/datastores/workspaceblobstore/paths/data/\",\n",
    "                        mode=InputOutputModes.RO_MOUNT\n",
    "                        ),\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([4]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        #\"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(range(2,8)),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"smander\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-SWEEP\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-HighDimSweep\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep 6D repo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>MaskPredictionwithCLIPVisGenome</td><td>yellow_house_ttxfx27r39</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/yellow_house_ttxfx27r39?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'yellow_house_ttxfx27r39', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://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@github.com/st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'a0a3448bb90672e567196fd60e3190e55de9c1b5', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '77cbba02-2a32-4aea-94fc-ecec244bb2f7'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/yellow_house_ttxfx27r39', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4c2a1a60>, 'serialize': <msrest.serialization.Serializer object at 0x7f9f4c409a00>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'MASKFINDER-STeveM', 'experiment_name': 'MaskPredictionwithCLIPVisGenome', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/yellow_house_ttxfx27r39?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.yellow_house_ttxfx27r39', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f9f4c409ca0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'yellow_house_ttxfx27r39', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4c2a1a60>, 'serialize': <msrest.serialization.Serializer object at 0x7f9f4c3ef5b0>, 'command': 'python ClipToMask.py --Cache_dir ./data --batch_size 2', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/6654aee1-4c0e-4adb-b401-c0753ce7b3c2/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/19', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f9f4d4dbee0>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'MASKFINDER-STeveM', 'is_deterministic': True, 'inputs': {}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.yellow_house_ttxfx27r39', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/yellow_house_ttxfx27r39?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9f4c2a1a60>}, 'instance_id': '7520d39d-a89d-4c06-b681-c4ef524c959c', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f9f4d4dbee0>, 'environment_variables': {}, 'environment': 'conda-6DIM:19', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "registered_model_name = \"Find Masks from CLIP Model\"\n",
    "job = command(\n",
    "    code=os.path.join(project_dir),  # location of source code\n",
    "    command=\"python ClipToMask.py --Cache_dir {} --batch_size {}\".format(\"./data\",2) ,#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"MaskPredictionwithCLIPVisGenome\",\n",
    "    display_name=\"MASKFINDER-STeveM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Inputs to job does not contain 'input_data' referenced in command\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:551\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     job\u001b[39m.\u001b[39mproperties \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mjob\u001b[39m.\u001b[39mproperties, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgit_props}\n\u001b[0;32m--> 551\u001b[0m rest_job_resource \u001b[39m=\u001b[39m to_rest_job_object(job)\n\u001b[1;32m    553\u001b[0m \u001b[39m# Make a copy of self._kwargs instead of contaminate the original one\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/to_rest_functions.py:42\u001b[0m, in \u001b[0;36m_\u001b[0;34m(job)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@to_rest_job_object\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JobBaseData:\n\u001b[0;32m---> 42\u001b[0m     rest_job \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39;49m_to_rest_object()\n\u001b[1;32m     43\u001b[0m     generate_defaults(job, rest_job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/sweep/sweep_job.py:247\u001b[0m, in \u001b[0;36mSweepJob._to_rest_object\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m search_space \u001b[39m=\u001b[39m {param: space\u001b[39m.\u001b[39m_to_rest_object() \u001b[39mfor\u001b[39;00m (param, space) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_space\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 247\u001b[0m validate_inputs_for_command(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrial\u001b[39m.\u001b[39;49mcommand, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs)\n\u001b[1;32m    248\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m search_space\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/_input_output_helpers.py:140\u001b[0m, in \u001b[0;36mvalidate_inputs_for_command\u001b[0;34m(command, inputs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_inputs_for_command\u001b[39m(command: \u001b[39mstr\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     _validate_inputs_for(\u001b[39m\"\u001b[39;49m\u001b[39mcommand\u001b[39;49m\u001b[39m\"\u001b[39;49m, command, inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_job/_input_output_helpers.py:130\u001b[0m, in \u001b[0;36m_validate_inputs_for\u001b[0;34m(input_consumer_name, input_consumer, inputs)\u001b[0m\n\u001b[1;32m    129\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInputs to job does not contain \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m referenced in \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m input_consumer_name\n\u001b[0;32m--> 130\u001b[0m \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    131\u001b[0m     message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(key),\n\u001b[1;32m    132\u001b[0m     no_personal_data_message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m[key]\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    133\u001b[0m     target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[1;32m    134\u001b[0m     error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    135\u001b[0m     error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m    136\u001b[0m )\n",
      "\u001b[0;31mValidationException\u001b[0m: Inputs to job does not contain 'input_data' referenced in command",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m sweep_job\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRun a hyperparameter sweep 6D repo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# submit the sweep\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m returned_sweep_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(sweep_job)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# get a URL for the status of the job\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m returned_sweep_job\u001b[39m.\u001b[39mservices[\u001b[39m\"\u001b[39m\u001b[39mStudio\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mendpoint\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:608\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmarshmallow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m SchemaValidationError\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n\u001b[0;32m--> 608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_exception_helper.py:295\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[0;32m--> 295\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(formatted_error)\n",
      "\u001b[0;31mException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) One or more fields are invalid\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Inputs to job does not contain 'input_data' referenced in command\u001b[39m\n\nResolutions: \n1) Double-check that all specified parameters are of the correct types and formats prescribed by the Job schema.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir ${{inputs.input_data}}\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"6DIMCOCOSWEEP2\",\n",
    "    display_name=\"6DIMSweepStephenMd1\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        \"prune\":Choice([1,0]),\n",
    "        \"projection\":Choice([\"None\",\"inv\",\"iinv\"]),\n",
    "        \"normlogits\":Choice([1,0]),\n",
    "        \"exactlabels\":Choice([1,0]),\n",
    "        \"meanloss\":Choice([1,0]),\n",
    "        \"maskLosses\":Choice([0,1,2]),\n",
    "        \"logitsversion\":Choice([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]),\n",
    "        \"precision\":Choice([32,16]),\n",
    "        \"codeversion\":Choice([6]),\n",
    "        \"transformer_layers\":Choice([3,4,5,6,8,12]),\n",
    "        \"transformer_heads\":Choice([16]),\n",
    "        \"embed_dim\":Choice([64,128,512]),\n",
    "        \"transformer_width\":Choice([64,128,512]),\n",
    "        \"devices\":Choice([1]),\n",
    "        \"accelerator\":Choice([\"gpu\"]),\n",
    "        \"log_path\":os.path.join(project_dir,\"./logs\"),\n",
    "        \"batch_size\":Choice(range(2,8)),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=500, max_concurrent_trials=20, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-SWEEP2\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-HighDimSweep\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep 6D repo\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
