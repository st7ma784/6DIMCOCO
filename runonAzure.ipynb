{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5\",\n",
    "    resource_group_name=\"sparc2023-workspace-xudyu-rg\",\n",
    "    workspace_name=\"sparc2023-ws-xudyu\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "No such file or directory: /home/user/dependencies/conda.yml",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/utils.py:265\u001b[0m, in \u001b[0;36mload_yaml\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     cm \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(source, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    266\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/user/dependencies/conda.yml'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m project_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dependencies_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(project_dir,\u001b[39m\"\u001b[39m\u001b[39mdependencies/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pipeline_job_env \u001b[39m=\u001b[39m Environment(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mconda-6DIM\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39menv for 6DIMCOCO experiments\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     conda_file\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dependencies_dir, \u001b[39m\"\u001b[39;49m\u001b[39mconda.yml\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     image\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#set OS var\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m env \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39menvironments\u001b[39m.\u001b[39mcreate_or_update(pipeline_job_env)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment with name \u001b[39m\u001b[39m{\u001b[39;00mpipeline_job_env\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m is registered to workspace, the environment version is \u001b[39m\u001b[39m{\u001b[39;00mpipeline_job_env\u001b[39m.\u001b[39mversion\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/environment.py:119\u001b[0m, in \u001b[0;36mEnvironment.__init__\u001b[0;34m(self, name, version, description, image, build, conda_file, tags, properties, datastore, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intellectual_property \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mintellectual_property\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    111\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    112\u001b[0m     version\u001b[39m=\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconda_file \u001b[39m=\u001b[39m conda_file\n\u001b[1;32m    120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage \u001b[39m=\u001b[39m image\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild \u001b[39m=\u001b[39m build\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/environment.py:172\u001b[0m, in \u001b[0;36mEnvironment.conda_file\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39m\"\"\"Set conda environment specification.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m:param value: A path to a local conda dependencies yaml file or a loaded yaml dictionary of dependencies.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m:type value: Union[str, os.PathLike, Dict]\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39m:return: None\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Dict):\n\u001b[0;32m--> 172\u001b[0m     value \u001b[39m=\u001b[39m _deserialize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_path, value, is_conda\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conda_file \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/environment.py:399\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(base_path, input, is_conda)\u001b[0m\n\u001b[1;32m    397\u001b[0m path \u001b[39m=\u001b[39m _resolve_path(base_path\u001b[39m=\u001b[39mbase_path, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m)\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m is_conda:\n\u001b[0;32m--> 399\u001b[0m     data \u001b[39m=\u001b[39m load_yaml(path)\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     data \u001b[39m=\u001b[39m load_file(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/utils.py:268\u001b[0m, in \u001b[0;36mload_yaml\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    267\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNo such file or directory: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 268\u001b[0m         \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    269\u001b[0m             message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(source),\n\u001b[1;32m    270\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m[file_path]\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    271\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    272\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mGENERAL,\n\u001b[1;32m    273\u001b[0m             error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mFILE_OR_FOLDER_NOT_FOUND,\n\u001b[1;32m    274\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[39m# source is a subclass of IO\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mreadable():\n",
      "\u001b[0;31mValidationException\u001b[0m: No such file or directory: /home/user/dependencies/conda.yml"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "project_dir=\".\"\n",
    "dependencies_dir = os.path.join(project_dir,\"dependencies/\")\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=\"conda-6DIM\",\n",
    "    description=\"env for 6DIMCOCO experiments\",\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.0-cuda11.7:15\"\n",
    "    #set OS var\n",
    "    \n",
    "    )\n",
    "\n",
    "env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_job_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m        self.opt_list(\"--num_trials\", default=0, type=int, tunable=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m        #self.opt_range('--neurons', default=50, type=int, tunable=True, low=1 '''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m registered_model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mContrastive trained DETR Model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m job \u001b[39m=\u001b[39m command(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     code\u001b[39m=\u001b[39mproject_dir,  \u001b[39m# location of source code\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython launch.py --num_trials 0 --dir \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m --log_path \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(project_dir,\u001b[39m\"\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m\"\u001b[39m),os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(project_dir,\u001b[39m\"\u001b[39m\u001b[39m./logs\u001b[39m\u001b[39m\"\u001b[39m)),\u001b[39m#--data ${{inputs.datadir}}\",\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     environment\u001b[39m=\u001b[39mpipeline_job_env\u001b[39m.\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpipeline_job_env\u001b[39m.\u001b[39mversion,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     compute\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparc-v100-low-priority-hv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     experiment_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m6DIMCOCO\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     display_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mContrastiveTraining-6D-StephenM\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     distribution\u001b[39m=\u001b[39m{\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPyTorch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprocess_count_per_instance\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnode_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstance_count\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline_job_env' is not defined"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "'''        #more info at https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser/\n",
    "        self.add_argument(\"--dir\",default=\"/nobackup/projects/bdlan05/smander3/data\",type=str)\n",
    "        self.add_argument(\"--log_path\",default=\"/nobackup/projects/bdlan05/smander3/logs/\",type=str)\n",
    "        self.opt_list(\"--learning_rate\", default=0.00001, type=float, options=[1e-3,1e-5, 1e-4,], tunable=True)\n",
    "        self.opt_list(\"--batch_size\", default=10, type=int, options=[6,8,10,12], tunable=True)\n",
    "        self.opt_list(\"--JSE\", default=0, type=int, options=[0], tunable=True)\n",
    "        self.opt_list(\"--prune\",default=False,type=bool,options=[True,False])\n",
    "        self.opt_list(\"--projection\",default=\"None\",type=str,options=[\"None\",\"inv\",\"iinv\"])\n",
    "        self.opt_list(\"--normlogits\",default=True,type=bool,options=[True,False])\n",
    "        self.opt_list(\"--exactlabels\",default=0,type=int,options=[1,0])\n",
    "        self.opt_list(\"--meanloss\",default=False,type=bool,options=[True,False])\n",
    "        self.opt_list(\"--maskLosses\",default=0,type=int,options=[0,1,2]) #1 and 2 often result in nan in labels?\n",
    "\n",
    "        self.opt_list(\"--logitsversion\",default=4,type=int,options=[0,1,2,3,4,5,6,7,8]) #1 and 2 often result in nan in labels?\n",
    "        self.opt_list(\"--precision\", default=32, options=[16], tunable=False)\n",
    "        self.opt_list(\"--codeversion\", default=6, type=int, options=[6], tunable=False)\n",
    "        self.opt_list(\"--transformer_layers\", default=8, type=int, options=[3,4,5,6], tunable=True)\n",
    "        self.opt_list(\"--transformer_heads\", default=16, type=int, options=[16], tunable=True)\n",
    "        self.opt_list(\"--embed_dim\", default=512, type=int, options=[128,512], tunable=True)\n",
    "        self.opt_list(\"--transformer_width\", default=512, type=int, options=[128,512], tunable=True)\n",
    "        self.opt_list(\"--devices\", default=1, type=int, options=[1], tunable=False)\n",
    "        self.opt_list(\"--accelerator\", default='gpu', type=str, options=['gpu'], tunable=False)\n",
    "        self.opt_list(\"--num_trials\", default=0, type=int, tunable=False)\n",
    "        #self.opt_range('--neurons', default=50, type=int, tunable=True, low=1 '''\n",
    "registered_model_name = \"Contrastive trained DETR Model\"\n",
    "job = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python launch.py --num_trials 0 --dir {} --log_path {} \".format(os.path.join(project_dir,\"./data\"),os.path.join(project_dir,\"./logs\")),#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\":\"+pipeline_job_env.version,\n",
    "    compute=\"sparc-v100-low-priority-hv\",\n",
    "    experiment_name=\"6DIMCOCO\",\n",
    "    display_name=\"ContrastiveTraining-6D-StephenM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "        \"node_count\": 1,\n",
    "        \"instance_count\": 1,\n",
    "    },\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data/6DIMCOCO/runonAzure.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bscc-ws-03/data/6DIMCOCO/runonAzure.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:903\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    889\u001b[0m     entity: T,\n\u001b[1;32m    890\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    891\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    892\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \n\u001b[1;32m    894\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39m        , ~azure.ai.ml.entities.Environment, ~azure.ai.ml.entities.Component, ~azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_ml_client.py:961\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparameter_dimensions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(custom_dimensions \u001b[39mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, dimensions) \u001b[39mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[39m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[39m.\u001b[39mactivity_info\u001b[39m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:610\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:542\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    544\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    545\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:894\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    896\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    897\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_job_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flatten_group_inputs(job\u001b[39m.\u001b[39minputs), job\u001b[39m.\u001b[39m_base_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1108\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n\u001b[1;32m   1107\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, Command):\n\u001b[0;32m-> 1108\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_command_job(job, resolver)\n\u001b[1;32m   1109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, ImportJob):\n\u001b[1;32m   1110\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_import_job(job, resolver)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:1146\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_command_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1137\u001b[0m         message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(job\u001b[39m.\u001b[39mcode),\n\u001b[1;32m   1138\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[1;32m   1145\u001b[0m     job\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[0;32m-> 1146\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1147\u001b[0m         azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m   1148\u001b[0m     )\n\u001b[1;32m   1149\u001b[0m job\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1150\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/entities/_assets/_artifacts/code.py:68\u001b[0m, in \u001b[0;36mCode.__init__\u001b[0;34m(self, name, version, description, tags, properties, path, ignore_file, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Only calculate hash for local files\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore_file \u001b[39m=\u001b[39m get_ignore_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath) \u001b[39mif\u001b[39;00m ignore_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ignore_file\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_sha256 \u001b[39m=\u001b[39m get_content_hash(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ignore_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:299\u001b[0m, in \u001b[0;36mget_content_hash\u001b[0;34m(path, ignore_file)\u001b[0m\n\u001b[1;32m    297\u001b[0m     actual_path \u001b[39m=\u001b[39m link_path \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misabs(link_path) \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), link_path)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(actual_path):\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash(_get_upload_files_from_folder(actual_path, ignore_file\u001b[39m=\u001b[39;49mignore_file))\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(actual_path):\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_file_list_content_hash([(actual_path, Path(actual_path)\u001b[39m.\u001b[39mname)])\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/site-packages/azure/ai/ml/_utils/_asset_utils.py:328\u001b[0m, in \u001b[0;36m_get_file_list_content_hash\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    327\u001b[0m     _hash\u001b[39m.\u001b[39mupdate((\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mencode())\n\u001b[0;32m--> 328\u001b[0m     _hash\u001b[39m.\u001b[39mupdate(\u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mgetsize(file_path))\u001b[39m.\u001b[39mencode())\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m file_path, file_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(file_list, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mlower()):\n\u001b[1;32m    330\u001b[0m     _hash \u001b[39m=\u001b[39m _get_file_hash(file_path, _hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/open-ce/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m     \u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/6DIMCOCO/../../blobs/a2a88b96561196777ca173b15309ea859f4d2ce0'"
     ]
    }
   ],
   "source": [
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/ashy_jicama_fdg5fnfg2h?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets define some sweeps, We really want to trial a load of values for all the following:\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python main.py\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"Testrelationshipdetection\",\n",
    "    display_name=\"SweepTest-StephenM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        #TO DO :: Should really be putting our data here as a path too \n",
    "        \"coco_path\":\"./data\",\n",
    "        \"batch_size\":Choice(range(2,3)),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=50, max_concurrent_trials=8, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-relationdetection\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-relationdetection\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep job for assessing how good MASK finding is from CLIP embeddings\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>MaskPredictionwithCLIPVisGenome</td><td>bubbly_sail_3354gjfc71</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/bubbly_sail_3354gjfc71?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&amp;tid=c681f89a-795a-4473-bc07-d86cb09d4312\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'name': 'bubbly_sail_3354gjfc71', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'git@github.com:st7ma784/6DIMCOCO.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '6c755a1964f9dd3e9a509a4b83e04c7edf17a894', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'd26ce080-90cd-464e-b61a-35719fe5b6d7'}, 'print_as_yaml': True, 'id': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/jobs/bubbly_sail_3354gjfc71', 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f42fe846460>, 'serialize': <msrest.serialization.Serializer object at 0x7f42fe8467f0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'MASKFINDER-STeveM', 'experiment_name': 'MaskPredictionwithCLIPVisGenome', 'compute': 'sparc-v100-low-priority', 'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/bubbly_sail_3354gjfc71?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bubbly_sail_3354gjfc71', 'mode': 'rw_mount'}}, 'inputs': {}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f42fe846610>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'bubbly_sail_3354gjfc71', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': '/data/6DIMCOCO', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f42fe846460>, 'serialize': <msrest.serialization.Serializer object at 0x7f42fe8468e0>, 'command': 'python ClipToMask.py --Cache_dir ./data --batch_size 2', 'code': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/codes/dbb567d7-69a5-41a7-b2e9-7b0d7f840c0e/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu/environments/conda-6DIM/versions/8', 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f42fe846070>, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'MASKFINDER-STeveM', 'is_deterministic': True, 'inputs': {}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.bubbly_sail_3354gjfc71', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': []}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://uksouth.api.azureml.ms/mlflow/v1.0/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourceGroups/sparc2023-workspace-xudyu-rg/providers/Microsoft.MachineLearningServices/workspaces/sparc2023-ws-xudyu?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/bubbly_sail_3354gjfc71?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f42fe846460>}, 'instance_id': '22cb9602-8705-4c87-8173-89c0416a0c24', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.PyTorchDistribution object at 0x7f42fe846070>, 'environment_variables': {}, 'environment': 'conda-6DIM:8', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "registered_model_name = \"Find Masks from CLIP Model\"\n",
    "job = command(\n",
    "    code=os.path.join(project_dir),  # location of source code\n",
    "    command=\"python ClipToMask.py --Cache_dir {} --batch_size {}\".format(\"./data\",2) ,#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"sparc-v100-low-priority\",\n",
    "    experiment_name=\"MaskPredictionwithCLIPVisGenome\",\n",
    "    display_name=\"MASKFINDER-STeveM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    ")\n",
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/red_moon_hrkt5mz9yz?wsid=/subscriptions/8db6e466-5fa0-4e7f-b009-c5e20e1a7fe5/resourcegroups/sparc2023-workspace-xudyu-rg/workspaces/sparc2023-ws-xudyu&tid=c681f89a-795a-4473-bc07-d86cb09d4312'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Create your command\n",
    "command_job_for_sweep = command(\n",
    "    code=project_dir,  # location of source code\n",
    "    command=\"python ClipToMask.py\",#--data ${{inputs.datadir}}\",\n",
    "    environment=pipeline_job_env.name+\"@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"Test CLIP Learning of MASKS\",\n",
    "    display_name=\"SweepTest-StephenM\",\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    inputs={\n",
    "        #TO DO :: Should really be putting our data here as a path too \n",
    "        \"version\":Choice([1,2]),\n",
    "        \"batch_size\":Choice(range(1,2)),\n",
    "        \"layers\":Choice([2,3,4])\n",
    "    },\n",
    ")\n",
    "\n",
    "# Call sweep() on your command job to sweep over your parameter expressions\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"sparc-v100-low-priority-hv\", \n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"train_loss\",#should really set this to something at the validation stage \n",
    "    goal=\"Minimize\",\n",
    ")\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=50, max_concurrent_trials=8, timeout=14400)\n",
    "\n",
    "# Set early stopping on this one\n",
    "sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"CLIP-MaskLearning-sweep\"\n",
    "sweep_job.experiment_name = \"StephenM-CLIP-Mask-Finding\"\n",
    "sweep_job.description = \"Run a hyperparameter sweep job for assessing how good MASK finding is from CLIP embeddings\"\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint\n",
    "\n",
    "# Download best trial model output\n",
    "#ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
